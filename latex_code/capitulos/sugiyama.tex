% !TeX root = ../libro.tex
% !TeX encoding = utf8

%\setchapterpreamble[c][0.75\linewidth]{%
%	\sffamily
%  Breve resumen del capítulo. TODO
%	\par\bigskip
%}

\chapter{Algoritmo de Sugiyama para códigos convolucionales sesgados RS}\label{ch:quinto-capitulo}

Una de las principales razones de por qué los códigos cíclicos de bloque son útiles es porque poseen una teoría matemática que nos permite diseñar algoritmos de decodificación muy eficientes. Un ejemplo es el algoritmo de Sugiyama estudiado en la sección \ref{sec:sugiyama} para la decodificación de códigos de bloque BCH.

Al tratar con códigos convolucionales, el algoritmo de Viterbi es, con diferencia, el algoritmo de decodificación más utilizado. Este algoritmo nos permite decodificar códigos convolucionales en canales binarios simétricos o con ruido gaussiano blanco aditivo. Hasta ahora, hemos visto que dotar a los códigos convolucionales de una estructura cíclica requiere de una multiplicación no conmutativa. Además, muchas de las propuestas de códigos cíclicos convolucionales no han conseguido aprovechar sus estructuras algebraicas para encontrar algoritmos de decodificación eficientes y prácticos, y se han limitado a proponer alternativas al algoritmo de Viterbi. Por ejemplo, los $\sigma$-CCC códigos propuestos por Roos \cite{Roos} no disponen del algoritmo de Euclides para la división.

En este capítulo vamos a estudiar un algoritmo de decodificación para los códigos convolucionales sesgados Reed-Solomon y es una exposición de los resultados descritos en \cite{gomez2017sugiyama}.

A lo largo de este capítulo, $\C$ será un código convolucional sesgado RS de distancia designada $\delta$, generado como un ideal por la izquierda de $\R_n$ por el polinomio 
$$ g = \left[x - \sigma^r(\beta),x - \sigma^{r+1}(\beta),\dots,x - \sigma^{r + \delta - 2}(\beta)\right]_\ell$$

para algún $r \geq 0$, donde $\beta$ se elige como en la Definición \ref{def:RS}. Por el Teorema \ref{th:dist}, la distancia de Hamming de $\C$ es exactamente $\delta$.

Sea $\tau = \left\lfloor \frac{\delta - 1}{2} \right\rfloor $ el número máximo de errores que el código puede corregir. Por simplicidad, supondremos que $r = 0$. Esto no es una restricción, ya que podemos escribir $\beta' = \sigma^{r}(\beta)$. De esta manera, $\beta' = (\alpha')^{-1}\sigma(\alpha')$, donde $\alpha' = \sigma^{r}(\alpha)$, y $\alpha'$ nos da también una base normal. Por tanto, 

$$ g = \left[x - \beta',x - \sigma(\beta'),\dots,x - \sigma^{\delta - 2}(\beta')\right]_\ell.$$

Sea $c \in \C$ una palabra código que se transmite por un canal con ruido. Entonces, se recibirá un polinomio $y = c + e$, donde

$$e = e_1x^{k_1} + e_2x^{k_2} + \cdots + e_\nu x^{k_\nu}, \quad \nu \leq \tau.$$

Definimos el \emph{polinomio localizador de errores} como

$$ \lambda = \left[ 1 - \sigma^{k_1}(\beta)x, 1 - \sigma^{k_2}(\beta)x, \dots, 1 - \sigma^{k_\nu}(\beta)x   \right]_r.$$


Veamos en primer lugar que $\lambda$ determina las posiciones que no tienen error. Para ello, veamos primero un lema que nos será de utilidad.


\begin{lema}\label{lema:aux}
Para cualquier subconjunto $\{t_1,\dots,t_m\} \subseteq \{0,1,\dots,n-1\}$, se cumple la igualdad

\begin{equation}
\left[ 1 - \sigma^{t_1}(\beta)x,\dots, 1-\sigma^{t_m}(x) \right]_r = \left[ x - \sigma^{t_1 - 1}(\beta^{-1}), \dots, x - \sigma^{t_m - 1}(\beta^{-1}) \right]_r.
\end{equation}

\end{lema}

\begin{proof}
Para cualquier $a \in \F(t)$, se cumple que

$$1 - ax = (x - \sigma^{-1}(a^{-1}))(-\sigma^{-1}(a)) \Leftrightarrow  x - \sigma^{-1}(a^{-1}) = (1 - ax)(-\sigma^{-1}(a^{-1})). $$

Por tanto, los polinomios del enunciado se dividen por la izquierda entre sí. De esta forma, el mínimo común múltiplo por la derecha coincide.

\end{proof}


\begin{proposicion}
El polinomio $1 - \sigma^d(\beta)x$ divide por la izquierda al polinomio localizador de errores $\lambda$ si y solo si $x - \sigma^{d-1}(\beta^{-1})$ divide por la izquierda a $\lambda$ si y solo si $d \in \{k_1,\dots, k_\nu\}$.
\end{proposicion}

\begin{proof}
Por el Lema \ref{lema:aux},  $1 - \sigma^d(\beta)x$ divide por la izquierda a $\lambda$ si y solo si $x - \sigma^{d-1}(\beta^{-1})$ divide por la izquierda a $\lambda$. Ahora, por el Lema \ref{lema:2}, $x - \sigma^{d-1}(\beta^{-1})$ divide por la izquierda a $\lambda$ si y solo si $d \in \{k_1,\dots,k_\nu\}$.
\end{proof}

Por tanto, una vez se conoce el polinomio localizador de errores $\lambda$, las posiciones donde se encuentran errores pueden ser localizadas siguiendo la siguiente regla: $d \in \{0,1,\dots,n-1\}$ es una posición de error si y solo si $\sigma^{d-1}(\beta^{-1})$ es una raíz por la izquierda de $\lambda$. Nótese que $\lambda$ se puede sustituir por cualquier polinomio en $\F(t)[x;\sigma]$ obtenido de la multiplicación por la derecha de $\lambda$ por un elemento $a \in \F(t)\backslash \{0\}$.

Dado $j \in \{1,\dots,\nu\}$, $\lambda = (1 - \sigma^{k_j}(\beta)x)p_j$ para algún polinomio $p_j \in \F(t)[x;\sigma]$ con grado $\nu - 1$, definimos el \emph{polinomio evaluador de errores} como $\omega = \sum_{j=1}^{\nu}e_j\sigma^{k_j}(\alpha)p_j$. Una vez conocemos el polinomio localizador de errores y el polinomio evaluador de errores, podemos calcular los valores $e_1,e_2,\dots,e_\nu$ resolviendo un sistema lineal y de esta manera, determinar completamente el error $e$. Observamos también que $\gr(\omega) < \nu$.

Por último, para cada $i \in \{0,\dots,n-1\}$, el $i$-ésimo síndrome $S_i$ de un polinomio recibido $y = \sum_{j=0}^{n-1}y_jx^j$ se define como el resto de la división por la izquierda de $y$ por $x - \sigma^i(\beta)$. Observamos que $S_i$ es la evaluación por la derecha de $y$ en $\sigma^i(\beta)$. Siempre que $i \in \{0,\dots,2\tau - 1\}$ las evaluaciones por la derecha de la palabra código $c$ son cero, y se sigue que

\begin{align*}
    S_i &= \sum_{j=0}^{n-1}y_jN_j(\sigma^i(\beta)) \\
        &= \sum_{j=1}^{\nu}e_jN_{k_j}(\sigma^i(\beta)) \\
        &= \sum_{j=1}^{\nu}e_j\sigma^i(N_{k_j}(\beta)) \\
        &= \sum_{j=1}^{\nu}e_j\sigma^i(\alpha^{-1})\sigma^{k_j + i}(\alpha) \\
        &= \sigma^i(\alpha^{-1})\sum_{j=1}^{\nu}
        e_j\sigma^{k_j + i}(\alpha).
\end{align*}

Por tanto,         
\begin{equation}\label{eq:6}
\sigma^i(\alpha)S_i = \sum_{j=1}^{\nu}e_j\sigma^{k_j+i}(\alpha)\end{equation} 

y llamamos al polinomio $S = \sum_{i=0}^{2\tau - 1}\sigma^i(\alpha)S_ix^i$ el \emph{polinomio de síndromes} de $y$.

\begin{teorema}
El polinomio localizador de errores $\lambda$ y el polinomio evaluador de errores $\omega$ satisfacen la siguiente ecuación clave no conmutativa

\begin{equation}
    \omega = S\lambda + x^{2\tau}u,
\end{equation}
donde $u \in \F(t)[x;\sigma]$ es de grado menor que $\nu$.
\end{teorema}

\begin{proof}
En primer lugar, observamos que $\F(t)[x;\sigma]$ puede verse como un subanillo del anillo sesgado de serie de potencias formales $\F(t)[[x;\sigma]]$ (ver \cite[Capítulo 1, Sección 4]{mcconnell2001noncommutative}). Dado $1 - ax \in \F(t)[x;\sigma]$ con $a \in \F(t)$ se tiene que en el anillo $\F(t)[[x;\sigma]]$, $(1-ax)^{-1} = \sum_{i \geq 0}N_i(a)x^i$. Por tanto,

$$p_j = (1-\sigma^{k_j}(\beta)x)^{-1}\lambda = \sum_{i \geq 0}N_i(\sigma^{k_j}(\beta))x^{i}\lambda$$ para cualquier $j \in \{1,\dots,\nu\}$. Entonces,

\begin{align*}
\omega &= \sum_{j=1}^{\nu}e_j\sigma^{k_j}(\alpha)p_j \\
       &= \sum_{j=1}^{\nu}e_j\sigma^{k_j}(\alpha)\sum_{i \geq 0}N_i(\sigma^{k_j}(\beta))x^{i}\lambda \\
       &= \sum_{i \geq 0}\left( \sum_{j=1}^{\nu}e_j\sigma^{k_j}(\alpha)N_i(\sigma^{k_j}(\beta))\right)x^i\lambda \\
       &= \sum_{i \geq 0}\left( \sum_{j=1}^{\nu}e_j\sigma^{k_j}(\alpha)\sigma^{k_j}(N_i(\beta))\right)x^i\lambda \qquad (\text{Proposición \ref{prop:norma}})\\
       &= \sum_{i \geq 0}\left( \sum_{j=1}^{\nu}e_j\sigma^{k_j}(\alpha)\sigma^{k_j}(\alpha^{-1}\sigma^i(\alpha))\right)x^i\lambda \\
       &= \sum_{i \geq 0}\left(\sum_{j=1}^{\nu}e_j\sigma^{k_j+i}(\alpha)\right)x^i\lambda \\
       &= \sum_{i=0}^{2\tau - 1}\left(\sum_{j=1}^{\nu}e_j\sigma^{k_j+i}(\alpha)\right)x^i\lambda + \sum_{i \geq 2\tau}\left(\sum_{j=1}^{\nu}e_j\sigma^{k_j+i}(\alpha)\right)x^i\lambda \\
       &=  \sum_{i=0}^{2\tau - 1} \sigma^i(\alpha)S_ix_i\lambda + x^{2\tau}\sum_{h \geq 0}\left(\sum_{j=1}^{\nu} \sigma^{-2\tau}(e_j)\sigma^{k_j+h}(\alpha)\right)x^h\lambda \qquad (\text{donde se ha utilizado \eqref{eq:6}}) \\
       &= S\lambda + x^{2\tau}\sum_{j=1}^{\nu}\sigma^{-2\tau}(e_j)\sum_{h \geq 0}\sigma^{k_j + h}(\alpha)x^h\lambda \\
       &= S\lambda + x^{2\tau}\sum_{j=1}^{\nu}\sigma^{-2\tau}(e_j)\sigma^{k_j}(\alpha)\sum_{h \geq 0}N_h(\sigma^{k_j}(\alpha))x^h\lambda \\
       &= S\lambda +  x^{2\tau}\sum_{j=1}^{\nu}\sigma^{-2\tau}(e_j)\sigma^{k_j}(\alpha)(1 - \sigma^{k_j}(\alpha)x)^{-1}\lambda \\
       &= S\lambda +  x^{2\tau}\sum_{j=1}^{\nu}\sigma^{-2\tau}(e_j)\sigma^{k_j}(\alpha)p_j \\
       &= S\lambda + x^{2\tau}u,
\end{align*}

donde $u = \sum_{j=1}^{\nu}\sigma^{-2\tau}(e_j)\sigma^{k_j}(\alpha)p_j$.

\end{proof}

Procedemos ahora a resolver la ecuación clave. Para ello, haremos algo parecido a lo que hicimos en la sección \ref{sec:sugiyama}, con la diferencia de que esta vez utilizaremos el algoritmo extendido de Euclides por la derecha (AEED), el cual está detallado en \ref{alg:eucld}.

\begin{teorema}\label{th:ec}
La ecuación clave no conmutativa 

\begin{equation}\label{eq:key}
x^{2\tau}u + S\lambda = \omega
\end{equation}

es un múltiplo por la izquierda de la ecuación 

\begin{equation}\label{eq:key2}
x^{2\tau}u_I + Sv_I = r_I
\end{equation}

donde $u_I,v_I$ y $r_I$ son los coeficientes de Bezout devueltos por el AEED con $x^{2\tau}$ y $S$ como entradas, e $I$ es el índice determinado por las condiciones $\gr(r_{I-1}) \geq \tau$ y $\gr(r_I) < \tau$. En particular, $\lambda = v_Ig$ y $\omega = r_Ig$ para algún $g \in \F(t)[x;\sigma]$.
\end{teorema}

\begin{proof}
    Recordemos que $\gr(S) < 2\tau$, $\gr(\lambda) \leq \tau$ y $\gr(\omega) < \nu \leq \tau$, consecuentemente $\gr(u) < \tau$. Por otro lado, por el Lema \ref{lema:24}\textit{(vi)}, $\gr(v_I) + \gr(r_{I-1}) = 2\tau$, por tanto, $\gr(v_I) \leq \tau$.

    Consideremos el mínimo común múltiplo por la derecha $[\lambda,v_I]_r = \lambda a = v_Ib$, donde $a,b \in \F(t)[x;\sigma]$ con $\gr(a) \leq \gr(v_I) \leq \tau$ y $\gr(b) \leq \gr(\lambda) \leq \tau$. Entonces, $(a,b)_r = 1$. Por tanto, multiplicando por la derecha \eqref{eq:key} por $a$ y \eqref{eq:key2} por $b$ obtenemos:

    \begin{equation}\label{eq:key3}
        x^{2\tau}ua + S\lambda a = \omega a
    \end{equation}
        
y        
    \begin{equation}\label{eq:key4}
        x^{2\tau}u_Ib + Sv_Ib = r_Ib
    \end{equation}

Restando las ecuaciones \eqref{eq:key3} y \eqref{eq:key4} obtenemos

\begin{equation}
    x^{2\tau}(ua - u_Ib) = \omega a - r_Ib
\end{equation}

Esta igualdad, comparando grados, solo puede darse si $ua = u_Ib$ y $\omega a = r_Ib$. Como $(a,b)_r = 1$, se tiene que $[u,u_I]_r = ua = u_Ib$ y $[\omega,a]_r = \omega a = r_Ib$. En particular, $\gr(a) \leq \gr(r_I) < \tau$. Consideramos el mínimo común múltiplo por la izquierda $[a,b]_\ell = a'a = b'b$.  Como $[\lambda,v_I]_r$ es un múltiplo por la izquierda de $a$ y $b$, existe $m \in \F(t)[x;\sigma]$ tal que $[\lambda,v_I]_r = m[a,b]_\ell$. Así, $\lambda a = v_Ib = ma'a = mb'b$. Por tanto, $\lambda = ma'$ y $v_I = mb'$, y por ser mínimo común múltiplo, $(\lambda,v_I)_\ell = m$. De manera análoga, se prueba que existen $m',m'' \in \F(t)[x;\sigma]$ tales que $u_I = m'b'$ y $u = m'a'$, y que $r_I = m''b'$ y $\omega = m''a$. Sin embargo, por el Lema \ref{lema:24}\textit{(v)}, $(u_I,v_I)_r = 1$, por tanto $b'=1$. De esta forma, $b = a'a$ y obtenemos que $\lambda = v_Ia'$,$\omega = r_Ia'$ y $u = u_Ia'$. Lo que demuestras que \eqref{eq:key} es un múltiplo por la izquierda de la ecuación \eqref{eq:key2}, tal y como buscábamos.
        

\end{proof}

Observamos que si $(\lambda,\omega)_r = 1$, entonces el Teorema \ref{th:ec} nos da un procedimiento algorítmico para calcular tanto el polinomio localizador de errores como el polinomio evaluador de errores. Sin embargo, a diferencia de lo que pasaba con los códigos de bloque, existen algunos polinomios no conmutativos que pueden tener máximo común divisor no trivial. En \cite{gomez2017sugiyama} se demuestra que, como consecuencia del Lema \ref{lema:2}, esta condición es equivalente a que el grado de $v_I$ sea mayor que el número de posiciones de error encontradas. No obstante, es bastante raro que el algoritmo \ref{Sug} falle al decodificar. Existen métodos para tratar estos errores y decodificar los mensajes aun cuando ocurra este error, al que denominamos \textit{error de ecuación clave}. Sin embargo, en \cite[Th. 19]{gomez2017sugiyama} se demuestra que como consecuencia de trabajar en el cuerpo infinito $\F(t)$, la probabilidad teórica de que esto ocurra es cero y, por tanto, no merece la pena implementar métodos para corregirlo.

\begin{algorithm}[H]
    \caption{Algoritmo de Sugiyama para códigos convolucionales sesgados RS}\label{Sug}
    \begin{algorithmic}[1]
    \REQUIRE Un polinomio recibido $y=\sum_{i=0}^{n-1}y_ix^i$ obtenido tras la transmisión de una palabra código $c \in \C$, donde $\C$ es un código convolucional RS sesgado generado por $g=\left[\{x-\sigma^i(\beta)\}_{i=0, \ldots , \delta-2}\right]$ con capacidad de corrección de $\tau=\lfloor \frac{\delta-1}{2}\rfloor$ errores.
    \ENSURE Una palabra código $c'$, o \emph{error de ecuación clave}.
    \FOR{\(0 \leq i \leq 2\tau-1\)}
        \STATE $S_i\gets\sum_{j=0}^{n-1} y_jN_j(\sigma^i(\beta))$
    \ENDFOR
    \STATE $S\gets \sum_{i=0}^{2\tau-1} \sigma^i(\alpha)S_ix^i$
    \IF{$S=0$}
        \RETURN $y$
    \ENDIF
    \STATE $\{u_i,v_i,r_i\}_{i=0,\ldots , l}\gets \text{AEED}(x^{2\tau},S)$
    \STATE $I\gets$ primera iteración en AEED con $\gr(r_i)<\tau$
    \STATE $pos\gets \emptyset$
    \FOR{\(0 \leq i \leq n-1\)}
        \IF{$\sigma^{i-1}(\beta^{-1})$ es una raíz por la izquierda de $v_I$}
            \STATE $pos=pos  \cup  \{i\}$
        \ENDIF
    \ENDFOR
    \IF{$\deg v_I > \mathrm{Cardinal}(pos)$}\label{kef}
        \RETURN \emph{error ecuación clave}
    \ENDIF
    \FOR{\(j\in pos\)}
        \STATE $p_j\gets \operatorname{rquo}(v_I,1-\sigma^j(\beta)x)$
    \ENDFOR
    \STATE Resolver el sistema lineal $r_I=\sum_{j\in pos}e_j\sigma^{j}(\alpha) p_j$
    \STATE $e\gets \sum_{j\in pos} e_jx^j$
    \RETURN $y-e$
    \end{algorithmic}
\end{algorithm}

\begin{ejemplo}\label{ej:sugiyama}

Sea $\F = \F_8$ el cuerpo finito de ocho elementos generado sobre $\F_2$ por un elemento primitivo $a$ con $a^3 + a + 1 = 0$. Sea $\sigma : \F(t) \mapsto \F(t)$ el automorfismo definido por $\sigma(t) = \frac{1}{t+a}$.

El orden de $\sigma$ es 9 y, por tanto, operaremos en el anillo $\mathcal{R} = \F(t)[x;\sigma]/\langle x^9 - 1 \rangle.$

Tenemos que el elemento $\alpha = t$ da lugar a una base normal $\{\alpha,\sigma(\alpha),\dots,\sigma^8(\alpha)\}$ ya que 

$$\begin{vmatrix}
    t & \sigma(t) & \sigma^2(t) & \cdots & \sigma^{8}(t) \\
    \sigma(t) & \sigma^2(t) & \sigma^3(t) & \cdots & t\\
    \vdots & \vdots & \vdots & \ddots & \vdots \\
    \sigma^{8}(t) & t & \sigma(t) & \cdots & \sigma^{7}(t)
\end{vmatrix} \neq 0.$$

Si $\beta = \alpha^{-1}\sigma(\alpha) = \frac{1}{t^2 + at}$, el polinomio $g = \left[ \{x - \sigma^i(\beta)\}_{i=0,1,2,3,4} \right]_\ell$ genera un $[9,5]$-código convolucional sesgado Reed-Solomon $\C$. Su distancia de Hamming, en virtud del Teorema \ref{th:dist}, es $\delta = 5$ y puede corregir hasta $\tau = 2$ errores.

El polinomio generador de $\C$ es

\begin{equation}
    \begin{aligned}
    g = x^4 &+ \left( \frac{(a^2 + 1)t^5 + (a + 1)t^4 + a t + a^2 + a + 1}{t^5 + (a^2 + 1)t^4 + (a^2 + a + 1)t + a^2 + a} \right) x^3 \\
    &+ \left( \frac{(a + 1)t^6 + (a + 1)t^5 + (a^2 + a + 1)t^4 + t^2 + t + a^2}{t^6 + t^5 + a t^4 + (a^2 + a + 1)t^2 + (a^2 + a + 1)t + a^2 + 1} \right) x^2 \\
    &+ \left( \frac{a^2 t^7 + (a^2 + a + 1)t^6 + (a^2 + 1)t^5 + (a^2 + a + 1)t^4}{t^7 + a t^6 + t^5 + (a^2 + a)t^4 + (a^2 + a + 1)t^3 + (a^2 + 1)t^2 + (a^2 + a + 1)t + a^2} \right) x \\
    &+ \left( \frac{(a^2 + 1)t^6 + (a^2 + a)t^5 + (a^2 + a)t^4 + t^3 + (a^2 + 1)t^2 + t + a}{t^7 + (a^2 + a + 1)t^6 + a t^5 + a^2 t^4 + (a^2 + a + 1)t^3 + (a + 1)t^2 + (a^2 + 1)t + 1} \right)
\end{aligned}
\end{equation}
    
Supongamos que se recibe el mensaje 

\begin{equation}
    \begin{aligned}
    y = x^4 &+ \left( \frac{(a^2 + 1)t^5 + (a + 1)t^4 + a t + a^2 + a + 1}{t^5 + (a^2 + 1)t^4 + (a^2 + a + 1)t + a^2 + a} \right) x^3 \\
    &+ \left( \frac{(a + 1)t^6 + (a + 1)t^5 + (a^2 + a + 1)t^4 + t^2 + t + a^2}{t^6 + t^5 + a t^4 + (a^2 + a + 1)t^2 + (a^2 + a + 1)t + a^2 + 1} \right) x^2,
\end{aligned}
\end{equation}

el cual consiste en el polinomio generador sin los términos de grado $1$ y $0$. De esta manera, hay errores en dos posiciones y el algoritmo de Sugiyama debería ser capaz de corregirlos.

En primer lugar, calculamos el polinomio de síndromes:

\begin{equation}
    \begin{aligned}
    S = \sum_{i=0}^{2\tau - 1} \sigma^i(\alpha) S_i x^i = 
    & \left( \frac{(a^2 + a + 1)t^7 + (a + 1)t^6 + a^2 t^5 + (a^2 + 1)t^4 + (a^2 + 1)t^3 + t^2 + a t + a^2 + 1}{t^7 + a t^6 + t^5 + (a^2 + a)t^4 + (a^2 + a + 1)t^3 + (a^2 + 1)t^2 + (a^2 + a + 1)t + a^2} \right) x^3 \\
    &+ \left( \frac{(a^2 + a)t^8 + (a^2 + a)t^7 + a t^6 + a t^5 + a^2 t^4 + (a^2 + 1)t^3 + (a + 1)t^2 + a t + a^2 + a + 1}{t^8 + (a + 1)t^7 + (a + 1)t^6 + (a^2 + a + 1)t^5 + t^4 + a t^3 + a t^2 + (a + 1)t + a^2} \right) x^2 \\
    &+ \left( \frac{a t^7 + (a + 1)t^6 + a^2 t^5 + (a + 1)t^3 + (a^2 + 1)t^2 + (a^2 + 1)t + a^2 + 1}{t^7 + (a + 1)t^5 + a t^4 + (a^2 + a + 1)t^3 + a t + a^2 + 1} \right) x \\
    &+ \left( \frac{(a^2 + 1)t^7 + a^2 t^6 + a^2 t^5 + t^4 + a^2 t^3 + a^2 t^2 + t}{t^7 + (a + 1)t^5 + a t^4 + (a^2 + a + 1)t^3 + a t + a^2 + 1} \right)
    \end{aligned}
    \end{equation}

Ahora, aplicamos el algoritmo extendido de Euclides por la derecha hasta que obtengamos un resto de grado menor que $\tau = 2$, y obtenemos que las raíces por la izquierda de $v_I$ en el conjunto $\{\sigma^{i-1}(\beta^{-1})\}_{i=0,\dots,8}$ son $\sigma^{-1}(\beta^{-1})$ y $\sigma^0(\beta^{-1}) = \beta^{-1}$. Por tanto, existen errores en las posiciones $0$ y $1$.

Ahora debemos resolver el sistema lineal 

$$r_I = e_0\sigma^0(t)p_0 + e_1\sigma(t)p_1.$$ 

Una vez resuelto, obtenemos que los valores del error son:

\begin{equation}
    e_0 = \frac{(a^2 + 1)t^6 + (a^2 + a)t^5 + (a^2 + a)t^4 + t^3 + (a^2 + 1)t^2 + t + a}{t^7 + (a^2 + a + 1)t^6 + a t^5 + a^2 t^4 + (a^2 + a + 1)t^3 + (a + 1)t^2 + (a^2 + 1)t + 1}
    \end{equation}
    
    \begin{equation}
    e_1 = \frac{a^2 t^7 + (a^2 + a + 1)t^6 + (a^2 + 1)t^5 + (a^2 + a + 1)t^4}{t^7 + a t^6 + t^5 + (a^2 + a)t^4 + (a^2 + a + 1)t^3 + (a^2 + 1)t^2 + (a^2 + a + 1)t + a^2}
    \end{equation}

Por tanto, $e = e_0 + e_1x$ y el polinomio corregido es:

\begin{equation}
    \begin{aligned}
    y - e = x^4 &+ \left( \frac{(a^2 + 1)t^5 + (a + 1)t^4 + a t + a^2 + a + 1}{t^5 + (a^2 + 1)t^4 + (a^2 + a + 1)t + a^2 + a} \right) x^3 \\
    &+ \left( \frac{(a + 1)t^6 + (a + 1)t^5 + (a^2 + a + 1)t^4 + t^2 + t + a^2}{t^6 + t^5 + a t^4 + (a^2 + a + 1)t^2 + (a^2 + a + 1)t + a^2 + 1} \right) x^2 \\
    &+ \left( \frac{a^2 t^7 + (a^2 + a + 1)t^6 + (a^2 + 1)t^5 + (a^2 + a + 1)t^4}{t^7 + a t^6 + t^5 + (a^2 + a)t^4 + (a^2 + a + 1)t^3 + (a^2 + 1)t^2 + (a^2 + a + 1)t + a^2} \right) x \\
    &+ \left( \frac{(a^2 + 1)t^6 + (a^2 + a)t^5 + (a^2 + a)t^4 + t^3 + (a^2 + 1)t^2 + t + a}{t^7 + (a^2 + a + 1)t^6 + a t^5 + a^2 t^4 + (a^2 + a + 1)t^3 + (a + 1)t^2 + (a^2 + 1)t + 1} \right) = g,
\end{aligned}
\end{equation}

tal y como buscábamos.



    


    
    


    
    
    
    
\end{ejemplo}




\endinput
